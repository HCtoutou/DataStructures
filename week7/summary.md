## 摊还分析

- 分析二项队列操作
- 分析斜堆
- 介绍并分析斐波那契堆
- 分析伸展树

### 二项队列

一棵二项树的节点的秩等于它的儿子节点的个数，特别地，BK的根节点的秩为k。二项队列是堆序的二项树的集合，在这个集合中对于任意的k最多可以存在一棵二项树BK.

**声明：**N个元素的二项队列可以通过N次相继插入而以O(N)时间构成。

在BuildBinomialQueue例程运行期间，每一次插入有一个最坏情形运行时间O（log N），但是由于整个例程最多用到2N个单位的时间，因此这些插入的行为就像是每次使用不多于两个单位的时间。

**定理**：Insert，DeleteMin以及Merge对于二项队列的摊还运行时间分别是O(1),O(log N),O(log N)。

**证明：**位势函数是树的棵数。初始的位势函数为0，且位势总是非负的，因此摊还时间是实际时间的一个上界。对Insert的分析从上面的论证可以得到。对于Merge，假设两棵树分别有N1和N2个节点以及对应的T1和T2棵树。令N=N1+N2.执行合并的实际时间为O(log (N1)+log( N2))=O(log N)。在合并之后，最多可能存在log N棵树，因此位势最多可以增加O（log N）。这就给出一个摊还的界O(log N)。DeleteMin的界可用类似的方法得到。

### 斜堆

对于斜堆，我们知道关键的操作是合并。为了合并两个斜堆，我们把它们的右路径合并并使之成为新的左路径。对于新路径上的每一个节点，除去最后一个，老的左子树作为右子树而附于其上。在新的左路径上的最后节点已知没有右子树，因此给他一棵右子树就不明智了。我们所要考虑的界不依赖于这个例外，如果例程是递归地编写的，那么这又是自然要发生的情况。

我们知道一次合并的效果是处在右路径上的每一个节点都被移动到左路径上，而其原左儿子变成新的右儿子。一种想法是把每一个节点算入为右节点或左节点来分类，这要看节点是右儿子还是不是右儿子来定，这时我们把右节点的个数作为位势函数。虽然位势初始时为0并且总是非负的，但是问题在于这种位势在一次合并之后并不减少从而不能恰当的反应在数据结构中的储备量。这样的结果使该位势函数不能够用来证明所要求的界。

一个类似的想法是把节点分成重节点或轻节点，这要看任意节点的右子树上的节点是否比左子树上的节点多来确定。

**定义：**一个节点p如果其右子树的后裔数至少是该p的后裔总数的一半，则称节点p是重的，否则称之为轻的。注意，一个节点的后裔个数包括该节点本身。

**定理：**合并两个斜堆的摊还时间为O(log N)。

### 斐波那契堆

斐波那契堆是以O(1)摊还时间支持所有基本的堆操作的一种数据结构，但DeleteMin和Delete除外，它们花费O(log N)的摊还时间。

斐波那契堆通过添加两个新的观念推广了二叉堆：

- DecreaseKey的一种不同的实现方法：我们以前看到的那种方法是把元素朝向根节点上滤。对于这种方法似乎没有理由期望O(1)的摊还时间界，因此需要一种新的方法。
- 懒惰合并：只有当两个堆需要合并时才进行合并。这类似于懒惰删除。对于懒惰合并，Merge是低廉的，但是因为懒惰合并并不实际把树结合在一起，所以DeleteMin操作可能会遇到许多的树，从而使这种操作的代价高昂。任何一次DeleteMin都可能花费线性时间，但是总能够把时间归咎到前面的一些Merge操作中去。特别的，一次昂贵的DeleteMin必须在其前面要有大量的非常低廉的Merge操作，它们能够存储额外的位势。

**定理：斐波那契堆中任意节点的秩为O(log N)。**

### 伸展树

伸展树的出发点是这样的：考虑到局部性原理（刚被访问的内容下次可能仍会被访问，查找次数多的内容可能下一次会被访问），为了使整个查找时间更小，被查频率高的那些节点应当经常处于靠近树根的位置。这样，很容易得想到以下这个方案：每次查找节点之后对树进行重构，把被查找的节点搬移到树根，这种自调整形式的二叉查找树就是伸展树。每次对伸展树进行操作后，它均会通过旋转的方法把被访问节点旋转到树根的位置。

我们知道，对节点X任意的树操作所需的时间正比于从根到X的路径上的节点的个数。如果我们把每个单旋转操作记为一次旋转，把每个之字形操作或一字形操作记为两次旋转，那么任何访问的花费等于1加上旋转的次数。



## 高级数据结构及其实现

- 在适当的时候非递归的自顶向下（而不是从低向上）的查找树的各种实现方法。
- 详细，优化的尤其是利用标记节点的实现方法。

### 自顶向下伸展树

伸展树，或者叫自适应查找树，是一种用于保存有序集合的简单高效的数据结构。伸展树实质上是一个二叉查找树。允许查找，插入，删除，删除最小，删除最大，分割，合并等许多操作，这些操作的时间复杂度为O(logN)。由于伸展树可以适应需求序列，因此他们的性能在实际应用中更优秀。
伸展树支持所有的二叉树操作。伸展树不保证最坏情况下的时间复杂度为O(logN)。伸展树的时间复杂度边界是均摊的。尽管一个单独的操作可能很耗时，但对于一个任意的操作序列，时间复杂度可以保证为O(logN)。
**AVLTree的缺点：**
1、平衡查找树每个节点都需要保存额外的信息（自底向上的实现方式同样保存了额外信息）。
2、难于实现，因此插入和删除操作复杂度高，且是潜在的错误点。
3、对于简单的输入，性能并没有什么提高。
**平衡查找树可以提高性能的地方：**
1、平衡查找树在最差、平均和最坏情况下的时间复杂度在本质上是相同的。
2、对一个节点的访问，如果第二次访问的时间小于第一次访问，将是非常好的事情。
3、90-10法则。在实际情况中，90%的访问发生在10%的数据上。
4、处理好那90%的情况就很好了。

#### 自顶向下旋转

在自底向上的伸展树中，我们需要求一个节点的父节点和祖父节点，因此这种伸展树难以实现或者需要额外的信息。因此，我们可以构建自顶向下的伸展树。
    当我们沿着树向下搜索某个节点X的时候，我们将搜索路径上的节点及其子树移走。我们构建两棵临时的树──左树和右树。没有被移走的节点构成的树称作中树。在伸展操作的过程中：
1、当前节点X是中树的根。
2、左树L保存小于X的节点。
3、右树R保存大于X的节点。
开始时候，X是树T的根，左右树L和R都是空的。和前面的自下而上相同，自上而下也分三种情况：

- 在搜索到X的时候，要查的节点比X小，并且Y等于要查找的节点（这种方式其实可以合并在zigzag情况之中）。因此Y是下一步要查找的节点，因此Y变成新的中树的树根，X及其右子树被移动到右树上。很显然，右树上的节点都大于所要查找的节点。注意X被放置在右树的最小的位置，即右树最小节点的左孩子指针上。因为X及其子树比原先的右树中所有的节点都要小。这是由于越是在路径前面被移动到右树的节点，其值越大
- 所查找的节点在Z的子树中，也就是，所查找的节点比X和Y都小。所以要将X，Y及其右子树都移动到右树中。首先是Y绕X右旋，然后将Z变成新的中树根节点。将Y及其子树移到右树中。注意右树中挂载点的位置。
- 先将X及其左子树连接到右树上，然后变成了zag的情况。接下来就可以很轻松的解决了
- **合并**：将中树的左右子树分别连接到左树的右子树和右树的左子树上。将左右树作为X的左右子树。重新最成了一所查找的节点为根的树。



```c
//右旋
SplayTree RightSingleRotate(Position T)
{
	SplayTree k1;

	k1 = T->Left;
	T->Left = k1->Right;
	k1->Right = T;
	return k1;
}
```

```c
//左旋
SplayTree LeftSingleRotate(Position k1)
{
	Position k2;

	k2 = k1->Right;
	k1->Right = k2->Left;
	k2->Left = k1;
	return k2;
}
```



### 红黑树

历史上AVL树流行的另一变种是红黑树。对红黑树的操作在最坏的情形下花费O(log N)时间，而且我们将看到，（对于插入操作）一种慎重的非递归实现可以相对容易的完成

红黑树是具有下列着色性质的二叉查找树：

1. 每一个节点或者着红色，或者着黑色。
2. 根是黑色的。
3. 如果一个节点是红色的，那么它的子节点必须是黑色的。
4. 从一个节点到一个NULL指针的每一条路径必须包含相同数目的黑色节点。

着色法则的一个推论是，红黑树的高度最多是2log（N+1）。因此，查找保证是一种对数的操作。

#### 自底向上插入

如果新插入的项的父节点是黑色的，那么插入完成。如果父节点是红色的，那么有几种情形需要考虑。首先，假设这个父节点的兄弟是黑的（我们采纳约定：NULL节点都是黑色的）。令X是新加的树叶，P是它的父节点，S是该父节点的兄弟，G是祖父节点。在这种情形只有X和P是红的，G是黑的，否则就会在插入前有两个相连的红色节点，违反了红黑树的法则。

如果S是红色的，那么会发生什么情况呢？在这种情况下，初始时从子树的根到C的路径上有一个黑色节点。在旋转之后，一定仍然还是只有一个黑色节点。但在两种情况下，在通向C路径上都有三个节点。由于只有一个可能是黑的，又由于我们不能有连续的红色节点，于是我们必须把S和子树的新根都涂成红色，而把G（以及第四个节点）涂成黑色。如果曾祖也是红色的那有怎么办呢？此时，我们可以将这个过程朝着根的方向上滤，就像对B树和二叉堆所做的那样，直到我们不再有两个相连的红色节点或者到达根处为止。

#### 自顶向下红黑树

上滤的实现需要用一个栈或用一些父指针保存路径。我们看到，如果我们使用一个自顶向下的过程，实际上是对红黑树应用从顶向下保证S不会是红的过程，则伸展树会更有效。

在向下的过程中当我们看到一个节点X有两个红儿子的时候，我们让X成为红的而让它的两个儿子是黑的。只有当X的父节点P也是红的时候这种翻转将破坏红黑的法则。

如果X的父节点的兄弟是红的会如何？这种可能已经被从顶向下过程中的行动所排除，因此X的父节点的兄弟不可能是红的。特别的，如果在沿树向下的过程中我们看到一个节点Y有两个红儿子，那么我们直到Y的孙子必然是黑色的，由于Y的儿子也要变成黑的，甚至在可能发生的旋转之后，因此我们将不会看到两层上另外的红节点。这样，当我们看到X，若X的父节点是红的，则X的父节点的兄弟不可能也是红的。

### 确定性跳跃表

1-2-3确定性跳跃表满足这样的性质：每一个间隙（除在头和尾之间可能的零间隙外）的容量尾1，2，3.

为了执行插入，我们必须保证当一个高度为h的新节点加入进来时不会产生具有四个高度为h的节点的间隙。实际上这很简单，采用类似于在红黑树中所做的自顶向下的方法即可。

设我们在第L层上，并要降到下一层去。如果要降到的间隙容量是3，那么我们提高该间隙的中间项使其高度为L，从而形成两个容量为1的间隙。由于这使得朝向删除的道路上消除了容量为3的间隙，因此插入是安全的。

删除的困难出现在间隙容量为1的情况。当我们看到将要下降到一个容量为1的间隙时,我们把这个间隙放大:或者是通过从相邻间隙(如果容量不为1)借来的方式,或者通过降低该间隙与邻间隙分开的节点的高度的方式。由于这两个都是容量为1的间隙。因此结果变成容量为3的间隙。

### AA树

在这一节我们描述二叉B树一种简单但却颇具竞争力的实现方法，这种树叫做BB树。BB树是带有一个附加条件的红黑树：一个节点最多可以有一个红儿子。为使编程容易，我们采纳一些法则。

1. 首先，我们加入只有右儿子可以是红的条件，这就消除了约一半的可能重新构建的情形。它也消除在删除算法中一个恼人的情形：如果一个内部节点只有一个儿子，那么这个儿子一定是右儿子（他刚好是红的），因为黑色左儿子将会违反红黑树的条件4.因此，我们总可以用一个内部节点的右子树中的最小节点代替该内部节点
2. 我们递归的编写这些过程
3. 我们把信息存在一个短整型数中，而不是把一个颜色位和每个节点一起存储。这个信息就是节点的层次。节点的层次：
   - 是1（若该节点是树叶）
   - 是它的父亲节点的层次（若该节点是红色）
   - 比他的父亲节点的层次少（若该节点是黑色的）



**连续两个水平方向链（horizontal link），所谓horizontal link是指一个结点跟它的右孩子结点的level相同（左孩子结点永远比它的父结点level小1）。这个规定其实相当于RB树中不能出现两个连续的红色结点。**

**向左的水平方向链（left horizontal link），也就是说一个结点最多只能出现一次向右的水平方向链。这是因为left horizontal link相当于左孩子能为红色结点，这在AA树的定义中是不允许的。**

在插入和删除操作中，可能会出现上面两个禁止发生的情况，这时候就需要通过树的旋转操作来纠正。AA树中只有两个基本操作：skew和split。前者用于纠正出现向左的水平方向链，后者用于纠正出现连续两个水平方向链的情况。skew就是一个右旋转，split是一个左旋转，但两者不是互逆的。skew操作之后可能引起1）的发生（当skew之前已经有一个右孩子的level跟当前结点的level相同），这时需要配合使用split操作。split操作的特点是新的子树的根节点level增加1, 从而会在它的父结点中出现1）(当它作为父结点的左孩子)或者在它的父结点中出现2）（当它作为父结点的右孩子而且父结点跟祖父结点的level相同），这时需要通过skew和split操作纠正这两种情况。

### treap树

Treap本身是一棵二叉搜索树，它的左子树和右子树也分别是一个Treap，和一般的二叉搜索树不同的是，Treap纪录一个额外的数据，就是优先级。Treap在以关键码构成二叉搜索树的同时，还满足堆的性质。这些优先级是是在结点插入时，随机赋予的，Treap根据这些优先级满足堆的性质。这样的话，Treap是有一个随机附加域满足堆的性质的二叉搜索树，其结构相当于以随机数据插入的二叉搜索树。其基本操作的期望时间复杂度为O(logn)。相对于其他的平衡二叉搜索树，Treap的特点是实现简单，且能基本实现随机平衡的结构。

### k-d树

k-d树也是二叉树，是用于分割多维空间的数据结构，所以其每一个节点是一个多维坐标。

在构造1维二叉查找树时，一个1维数据根据其与树的根结点和中间结点进行大小比较的结果来决定是划分到左子树还是右子树，同理，我们也可以按照这样的方式，将一个K维数据与Kd-tree的根结点和中间结点进行比较，只不过不是对K维数据进行整体的比较，而是选择某一个维度Di，然后比较两个K维数在该维度Di上的大小关系，即每次选择一个维度Di来对K维数据进行划分，相当于用一个垂直于该维度Di的超平面将K维数据空间一分为二，平面一边的所有K维数据在Di维度上的值小于平面另一边的所有K维数据对应维度上的值。也就是说，我们每选择一个维度进行如上的划分，就会将K维数据空间划分为两个部分，如果我们继续分别对这两个子K维空间进行如上的划分，又会得到新的子空间，对新的子空间又继续划分，重复以上过程直到每个子空间都不能再划分为止。以上就是构造Kd-Tree的过程，上述过程中涉及到两个重要步骤：

1. 划分时以选中维度的中位数来划分，小的为左节点，大的为右节点。
2. 选择维度的方法有最大方差法或顺序遍历法，这里采用顺序遍历法，即对于点（x1, x2, x3, x4 ....），第一次按x1的维度来切分，第二次按照x2的维度来切分，切刀最后一个维度之后又回到x1的维度。

### 配对堆

配对堆(Pairing Heap)是一个简单实用的min-heap结构（当然也可以做成max-heap）。它是一颗多路树(multiway tree)，类似于Leftist Heap和Skew Heap，但是与Binomial Tree和Fibonacci Heap不一样。它的基本操作是两个多路树的连接(link)，所以取名叫Pairing Heap。连接操作(参考以下实现中的方法linkPair)类似于Binomial Tree和Fibonacci Heap中的link操作，即将root key值最大的树作为key值最小的树的孩子（一般作为最左边的孩子，特别是Binomial Heap必须这样做），其复杂度是常数级。因为Pairing Heap只有一棵树，所以它的merge操作(类似于Fibonacci Heap中的union)也很简单，只需要link两棵树就可以了，平摊复杂度与Fibonacci Heap类似，都是常数级操作，而在Binomial Heap中需要union两个root lists，所以复杂度为O(logn)。



### 总结

这周学习的高级数据结构整体来说难度很大，导致我在学习的过程中遇到了很多困难，具体表现为某些代码的实现。由于考试的缘故，这周只完成了前三个高级数据结构的实现但并未进行整体测试。在之后的学习中还会不断的重新看这部分的内容并进行学习